{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":90995,"status":"ok","timestamp":1722250719432,"user":{"displayName":"Walter Nguyen","userId":"03409983746612432049"},"user_tz":-420},"id":"FjWvkZ0vsb4M","outputId":"46707a79-5867-43f8-b1d3-7e630bc8917d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.4.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ultralytics\n","  Downloading ultralytics-8.2.68-py3-none-any.whl.metadata (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m701.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.25.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.1+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.0-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.1)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Downloading ultralytics-8.2.68-py3-none-any.whl (828 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.2/828.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Downloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\n","Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.68 ultralytics-thop-2.0.0\n"]}],"source":["!pip install tensorflow\n","!pip install -q tfds-nightly tensorflow matplotlib\n","!pip install ultralytics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":212751,"status":"ok","timestamp":1722144983578,"user":{"displayName":"Walter Nguyen","userId":"03409983746612432049"},"user_tz":-420},"id":"7jV6kbVg0iVR","outputId":"dea3144e-d5b2-49ae-b161-2ba544d581bc"},"outputs":[],"source":["!unzip /content/drive/MyDrive/Food-detection/archive.zip -d /content/drive/MyDrive/Food-detection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-_v4rJ6ww-Ec"},"outputs":[],"source":["data_yaml_path = '/content/drive/MyDrive/Food-detection/Fruits-detection/data.yaml'\n","pretrained_path = '/content/drive/MyDrive/Food-detection/Fruits-detection/yolov8s.pt'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5002479,"status":"ok","timestamp":1722150217180,"user":{"displayName":"Walter Nguyen","userId":"03409983746612432049"},"user_tz":-420},"id":"GMZGbMYks3t8","outputId":"3d914d45-ef79-4ec3-f177-56878f8781c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING ⚠️ /content/drive/MyDrive/Food-detection/Fruits-detection/yolov8s.pt appears to require 'omegaconf', which is not in Ultralytics requirements.\n","AutoInstall will run now for 'omegaconf' but this feature will be removed in the future.\n","Recommend fixes are to train a new model using the latest 'ultralytics' package or to run a command with an official Ultralytics model, i.e. 'yolo predict model=yolov8n.pt'\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['omegaconf'] not found, attempting AutoUpdate...\n","Collecting omegaconf\n","  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n","Collecting antlr4-python3-runtime==4.9.* (from omegaconf)\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.0/117.0 kB 6.2 MB/s eta 0:00:00\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0.1)\n","Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.5/79.5 kB 240.7 MB/s eta 0:00:00\n","Building wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py): started\n","  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144552 sha256=dac9c7d36de61a4b59d4efff663112c437516986065ff11c3619d19e64962f14\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-dvyx2s9x/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: antlr4-python3-runtime, omegaconf\n","Successfully installed antlr4-python3-runtime-4.9.3 omegaconf-2.3.0\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 5.3s, installed 1 package: ['omegaconf']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","Ultralytics YOLOv8.2.67 🚀 Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/drive/MyDrive/Food-detection/Fruits-detection/yolov8s.pt, data=/content/drive/MyDrive/Food-detection/Fruits-detection/data.yaml, epochs=20, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=yolov8s_fruit, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/yolov8s_fruit\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 755k/755k [00:00<00:00, 21.6MB/s]"]},{"name":"stdout","output_type":"stream","text":["Overriding model.yaml nc=80 with nc=6\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":[" 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2118370  ultralytics.nn.modules.head.Detect           [6, [128, 256, 512]]          \n","Model summary: 225 layers, 11,137,922 parameters, 11,137,906 gradients, 28.7 GFLOPs\n","\n","Transferred 349/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/yolov8s_fruit', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6.25M/6.25M [00:00<00:00, 118MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Food-detection/Fruits-detection/train/labels... 7108 images, 0 backgrounds, 0 corrupt: 100%|██████████| 7108/7108 [02:34<00:00, 46.06it/s] "]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/Food-detection/Fruits-detection/train/images/3d8be4f881b8c54c_jpg.rf.0d7b6d095459cece040b47b246d807af.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/Food-detection/Fruits-detection/train/images/3d8be4f881b8c54c_jpg.rf.64e869a9bedd5f012cc2a1129c6ca229.jpg: 1 duplicate labels removed\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/Food-detection/Fruits-detection/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"name":"stderr","output_type":"stream","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Food-detection/Fruits-detection/valid/labels... 914 images, 0 backgrounds, 0 corrupt: 100%|██████████| 914/914 [00:13<00:00, 66.25it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/Food-detection/Fruits-detection/valid/images/3d3ddc3054b32eb7_jpg.rf.03e7789aaf5212e2634b84ef502e0832.jpg: 1 duplicate labels removed\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/Food-detection/Fruits-detection/valid/labels.cache\n","Plotting labels to runs/detect/yolov8s_fruit/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/yolov8s_fruit\u001b[0m\n","Starting training for 20 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       1/20      2.42G      1.007      2.076      1.266         26        640: 100%|██████████| 889/889 [04:07<00:00,  3.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:16<00:00,  3.62it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227      0.344      0.278      0.216      0.111\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       2/20      2.37G     0.9896      1.681      1.268         21        640: 100%|██████████| 889/889 [03:55<00:00,  3.77it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:15<00:00,  3.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227      0.329      0.309      0.229       0.13\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       3/20      2.58G     0.9933       1.63      1.261          8        640: 100%|██████████| 889/889 [03:52<00:00,  3.82it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:14<00:00,  3.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227       0.45      0.337      0.318      0.189\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       4/20      2.39G     0.9439      1.526      1.241         20        640: 100%|██████████| 889/889 [03:47<00:00,  3.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:14<00:00,  3.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227      0.396      0.324      0.277      0.155\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       5/20      2.41G     0.9091      1.392      1.218         16        640: 100%|██████████| 889/889 [03:41<00:00,  4.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:13<00:00,  4.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227      0.478      0.344      0.336       0.19\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       6/20       2.4G     0.8716      1.317      1.193         22        640: 100%|██████████| 889/889 [03:44<00:00,  3.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:15<00:00,  3.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227       0.53      0.388       0.39      0.245\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       7/20      2.51G     0.8436       1.23      1.176         34        640: 100%|██████████| 889/889 [03:46<00:00,  3.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:15<00:00,  3.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227      0.561      0.376       0.41      0.248\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       8/20      2.39G     0.8209      1.199      1.163         28        640: 100%|██████████| 889/889 [03:45<00:00,  3.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:15<00:00,  3.82it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227       0.53      0.416      0.413      0.256\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       9/20      2.37G     0.8049      1.144       1.15         52        640: 100%|██████████| 889/889 [03:44<00:00,  3.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:15<00:00,  3.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227      0.519      0.437      0.436      0.278\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      10/20      2.41G     0.7858      1.098      1.144         27        640: 100%|██████████| 889/889 [03:44<00:00,  3.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:15<00:00,  3.82it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227      0.564      0.447      0.467      0.305\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"name":"stderr","output_type":"stream","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      11/20      2.35G      0.788       1.03      1.141          6        640: 100%|██████████| 889/889 [03:39<00:00,  4.05it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:14<00:00,  4.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227       0.53      0.406      0.422      0.266\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      12/20      2.39G     0.7769     0.9577      1.125         20        640: 100%|██████████| 889/889 [03:34<00:00,  4.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:14<00:00,  4.13it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227      0.583      0.394       0.43      0.273\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      13/20      2.39G     0.7528     0.9026      1.106          7        640: 100%|██████████| 889/889 [03:38<00:00,  4.07it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:14<00:00,  3.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227      0.594      0.409      0.448      0.292\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      14/20      2.39G      0.729     0.8504      1.095          9        640: 100%|██████████| 889/889 [03:32<00:00,  4.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:13<00:00,  4.15it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227      0.569      0.432       0.46      0.302\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      15/20      2.39G     0.7195     0.8209      1.088         17        640: 100%|██████████| 889/889 [03:36<00:00,  4.12it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:15<00:00,  3.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227      0.586      0.449      0.483      0.324\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      16/20      2.37G     0.7103     0.7767      1.079         28        640: 100%|██████████| 889/889 [03:35<00:00,  4.12it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:15<00:00,  3.86it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227      0.622      0.432      0.487      0.329\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      17/20      2.39G     0.6891      0.732      1.065         36        640: 100%|██████████| 889/889 [03:36<00:00,  4.10it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:15<00:00,  3.82it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227       0.62      0.424      0.486      0.324\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      18/20      2.38G     0.6668     0.6944      1.052          6        640: 100%|██████████| 889/889 [03:36<00:00,  4.11it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:12<00:00,  4.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227      0.605      0.478      0.514      0.347\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      19/20      2.35G      0.657     0.6561      1.048         27        640: 100%|██████████| 889/889 [03:36<00:00,  4.10it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:15<00:00,  3.83it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227      0.582      0.473      0.508      0.347\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      20/20      2.39G     0.6459     0.6285      1.038         11        640: 100%|██████████| 889/889 [03:37<00:00,  4.08it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:12<00:00,  4.54it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227      0.615      0.472      0.512       0.35\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","20 epochs completed in 1.327 hours.\n","Optimizer stripped from runs/detect/yolov8s_fruit/weights/last.pt, 22.5MB\n","Optimizer stripped from runs/detect/yolov8s_fruit/weights/best.pt, 22.5MB\n","\n","Validating runs/detect/yolov8s_fruit/weights/best.pt...\n","Ultralytics YOLOv8.2.67 🚀 Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 11,127,906 parameters, 0 gradients, 28.4 GFLOPs\n"]},{"name":"stderr","output_type":"stream","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:18<00:00,  3.17it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        914       3227      0.615      0.472      0.513      0.351\n","                 Apple        188        557      0.634      0.465      0.516      0.366\n","                Banana        167        390      0.621      0.505      0.535      0.325\n","                 Grape        199        809       0.58      0.387       0.41      0.275\n","                Orange        197       1100      0.596      0.392      0.456      0.301\n","             Pineapple         77        154      0.601        0.5      0.512      0.354\n","            Watermelon        107        217       0.66      0.581      0.648      0.482\n","Speed: 0.5ms preprocess, 5.1ms inference, 0.0ms loss, 3.4ms postprocess per image\n","Results saved to \u001b[1mruns/detect/yolov8s_fruit\u001b[0m\n"]}],"source":["from ultralytics import YOLO\n","\n","from IPython.display import display, Image\n","\n","# Load the model.\n","model = YOLO(pretrained_path)\n","\n","# Training.\n","results = model.train(\n","   data=data_yaml_path,\n","   imgsz=640,\n","   epochs=20,\n","   batch=8,\n","   name='yolov8s_fruit'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":420},"executionInfo":{"elapsed":33657,"status":"ok","timestamp":1722152424449,"user":{"displayName":"Walter Nguyen","userId":"03409983746612432049"},"user_tz":-420},"id":"v_90sCW52mAX","outputId":"274d57e1-7922-412d-c443-491da54da31e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.2.67 🚀 Python-3.10.12 torch-2.3.1+cu121 CPU (Intel Xeon 2.00GHz)\n","Model summary (fused): 168 layers, 11,127,906 parameters, 0 gradients, 28.4 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/detect/yolov8s_fruit/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 10, 8400) (0.0 MB)\n","\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.15.0...\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 17...\n","\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.32...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.9s, saved as 'runs/detect/yolov8s_fruit/weights/best.onnx' (42.8 MB)\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.22.3...\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ✅ 30.8s, saved as 'runs/detect/yolov8s_fruit/weights/best_saved_model' (106.9 MB)\n","\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.15.0...\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ✅ 0.0s, saved as 'runs/detect/yolov8s_fruit/weights/best_saved_model/best_float32.tflite' (42.7 MB)\n","\n","Export complete (33.0s)\n","Results saved to \u001b[1m/content/runs/detect/yolov8s_fruit/weights\u001b[0m\n","Predict:         yolo predict task=detect model=runs/detect/yolov8s_fruit/weights/best_saved_model/best_float32.tflite imgsz=640  \n","Validate:        yolo val task=detect model=runs/detect/yolov8s_fruit/weights/best_saved_model/best_float32.tflite imgsz=640 data=/content/drive/MyDrive/Food-detection/Fruits-detection/data.yaml  \n","Visualize:       https://netron.app\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'runs/detect/yolov8s_fruit/weights/best_saved_model/best_float32.tflite'"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["model.export(format=\"tflite\")"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":393,"status":"ok","timestamp":1722250741488,"user":{"displayName":"Walter Nguyen","userId":"03409983746612432049"},"user_tz":-420},"id":"jhTlad2BPxV8"},"outputs":[],"source":["\n","\n","from IPython.display import display, Javascript, Image\n","# JavaScript to properly create our live video stream using our webcam as input\n","\n","def video_stream():\n","  js = Javascript('''\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","\n","    var pendingResolve = null;\n","    var shutdown = false;\n","\n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","\n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","\n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","\n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"Status:\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","\n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","\n","      const instruction = document.createElement('div');\n","      instruction.innerHTML =\n","          '' +\n","          'Bấm vào video để dừng';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 640; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","\n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","\n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","\n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","\n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","\n","      return {'create': preShow - preCreate,\n","              'show': preCapture - preShow,\n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    ''')\n","\n","  display(js)\n","\n","def video_frame(label, bbox):\n","  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n","  return data\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":382,"status":"ok","timestamp":1722250744573,"user":{"displayName":"Walter Nguyen","userId":"03409983746612432049"},"user_tz":-420},"id":"I-yy7A2j0Xm0"},"outputs":[],"source":["# function to convert the JavaScript object into an OpenCV image\n","def js_to_image(js_reply):\n","  \"\"\"\n","  Params:\n","          js_reply: JavaScript object containing image from webcam\n","  Returns:\n","          img: OpenCV BGR image\n","  \"\"\"\n","  # decode base64 image\n","  image_bytes = b64decode(js_reply.split(',')[1])\n","  # convert bytes to numpy array\n","  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n","  # decode numpy array into OpenCV BGR image\n","  img = cv2.imdecode(jpg_as_np, flags=1)\n","\n","  return img\n","\n","# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n","def bbox_to_bytes(bbox_array):\n","  \"\"\"\n","  Params:\n","          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n","  Returns:\n","        bytes: Base64 image byte string\n","  \"\"\"\n","  # convert array into PIL image\n","  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n","  iobuf = io.BytesIO()\n","  # format bbox into png for return\n","  bbox_PIL.save(iobuf, format='png')\n","  # format return string\n","  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n","\n","  return bbox_bytes"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":18990,"status":"ok","timestamp":1722250767029,"user":{"displayName":"Walter Nguyen","userId":"03409983746612432049"},"user_tz":-420},"id":"GIz8LVvozqFY","outputId":"22940046-6ec9-4845-d314-7eb5381b7380"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n"]},{"data":{"application/javascript":"\n    var video;\n    var div = null;\n    var stream;\n    var captureCanvas;\n    var imgElement;\n    var labelElement;\n    \n    var pendingResolve = null;\n    var shutdown = false;\n    \n    function removeDom() {\n       stream.getVideoTracks()[0].stop();\n       video.remove();\n       div.remove();\n       video = null;\n       div = null;\n       stream = null;\n       imgElement = null;\n       captureCanvas = null;\n       labelElement = null;\n    }\n    \n    function onAnimationFrame() {\n      if (!shutdown) {\n        window.requestAnimationFrame(onAnimationFrame);\n      }\n      if (pendingResolve) {\n        var result = \"\";\n        if (!shutdown) {\n          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n        }\n        var lp = pendingResolve;\n        pendingResolve = null;\n        lp(result);\n      }\n    }\n    \n    async function createDom() {\n      if (div !== null) {\n        return stream;\n      }\n\n      div = document.createElement('div');\n      div.style.border = '2px solid black';\n      div.style.padding = '3px';\n      div.style.width = '100%';\n      div.style.maxWidth = '600px';\n      document.body.appendChild(div);\n      \n      const modelOut = document.createElement('div');\n      modelOut.innerHTML = \"Status:\";\n      labelElement = document.createElement('span');\n      labelElement.innerText = 'No data';\n      labelElement.style.fontWeight = 'bold';\n      modelOut.appendChild(labelElement);\n      div.appendChild(modelOut);\n           \n      video = document.createElement('video');\n      video.style.display = 'block';\n      video.width = div.clientWidth - 6;\n      video.setAttribute('playsinline', '');\n      video.onclick = () => { shutdown = true; };\n      stream = await navigator.mediaDevices.getUserMedia(\n          {video: { facingMode: \"environment\"}});\n      div.appendChild(video);\n\n      imgElement = document.createElement('img');\n      imgElement.style.position = 'absolute';\n      imgElement.style.zIndex = 1;\n      imgElement.onclick = () => { shutdown = true; };\n      div.appendChild(imgElement);\n      \n      const instruction = document.createElement('div');\n      instruction.innerHTML = \n          '' +\n          'Bấm vào video để dừng';\n      div.appendChild(instruction);\n      instruction.onclick = () => { shutdown = true; };\n      \n      video.srcObject = stream;\n      await video.play();\n\n      captureCanvas = document.createElement('canvas');\n      captureCanvas.width = 640; //video.videoWidth;\n      captureCanvas.height = 640; //video.videoHeight;\n      window.requestAnimationFrame(onAnimationFrame);\n      \n      return stream;\n    }\n    async function stream_frame(label, imgData) {\n      if (shutdown) {\n        removeDom();\n        shutdown = false;\n        return '';\n      }\n\n      var preCreate = Date.now();\n      stream = await createDom();\n      \n      var preShow = Date.now();\n      if (label != \"\") {\n        labelElement.innerHTML = label;\n      }\n            \n      if (imgData != \"\") {\n        var videoRect = video.getClientRects()[0];\n        imgElement.style.top = videoRect.top + \"px\";\n        imgElement.style.left = videoRect.left + \"px\";\n        imgElement.style.width = videoRect.width + \"px\";\n        imgElement.style.height = videoRect.height + \"px\";\n        imgElement.src = imgData;\n      }\n      \n      var preCapture = Date.now();\n      var result = await new Promise(function(resolve, reject) {\n        pendingResolve = resolve;\n      });\n      shutdown = false;\n      \n      return {'create': preShow - preCreate, \n              'show': preCapture - preShow, \n              'capture': Date.now() - preCapture,\n              'img': result};\n    }\n    ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","0: 640x640 1 Orange, 727.0ms\n","Speed: 9.6ms preprocess, 727.0ms inference, 22.5ms postprocess per image at shape (1, 3, 640, 640)\n","[ultralytics.engine.results.Results object with attributes:\n","\n","boxes: ultralytics.engine.results.Boxes object\n","keypoints: None\n","masks: None\n","names: {0: 'Apple', 1: 'Banana', 2: 'Grape', 3: 'Orange', 4: 'Pineapple', 5: 'Watermelon'}\n","obb: None\n","orig_img: array([[[77, 40, 36],\n","        [77, 40, 36],\n","        [81, 41, 36],\n","        ...,\n","        [46, 32, 38],\n","        [46, 32, 38],\n","        [46, 32, 38]],\n","\n","       [[77, 40, 36],\n","        [77, 40, 36],\n","        [79, 41, 36],\n","        ...,\n","        [46, 32, 38],\n","        [46, 32, 38],\n","        [46, 32, 38]],\n","\n","       [[77, 40, 36],\n","        [78, 41, 37],\n","        [80, 42, 37],\n","        ...,\n","        [46, 32, 38],\n","        [46, 32, 38],\n","        [46, 32, 38]],\n","\n","       ...,\n","\n","       [[ 0,  0,  0],\n","        [ 0,  0,  0],\n","        [ 0,  0,  0],\n","        ...,\n","        [ 0,  0,  0],\n","        [ 0,  0,  0],\n","        [ 0,  0,  0]],\n","\n","       [[ 0,  0,  0],\n","        [ 0,  0,  0],\n","        [ 0,  0,  0],\n","        ...,\n","        [ 0,  0,  0],\n","        [ 0,  0,  0],\n","        [ 0,  0,  0]],\n","\n","       [[ 0,  0,  0],\n","        [ 0,  0,  0],\n","        [ 0,  0,  0],\n","        ...,\n","        [ 0,  0,  0],\n","        [ 0,  0,  0],\n","        [ 0,  0,  0]]], dtype=uint8)\n","orig_shape: (640, 640)\n","path: 'image0.jpg'\n","probs: None\n","save_dir: 'runs/detect/predict'\n","speed: {'preprocess': 9.624004364013672, 'inference': 726.9794940948486, 'postprocess': 22.548913955688477}]\n"]}],"source":["%cd /content\n","from google.colab.output import eval_js\n","from google.colab.patches import cv2_imshow\n","from base64 import b64decode, b64encode\n","import numpy as np\n","import PIL\n","import io\n","import cv2\n","from keras.models import  load_model\n","from ultralytics import YOLO\n","\n","# start streaming video from webcam\n","video_stream()\n","# label for video\n","label_html = 'Đang lấy hình ảnh...'\n","# initialze bounding box to empty\n","bbox = ''\n","count = 0\n","\n","# Load model Nhận diện tiền\n","model_file_path = \"/content/drive/MyDrive/Food-detection/runs/detect/yolov8s_fruit/weights/best.pt\"\n","model = YOLO(model_file_path)\n","\n","classes = ['Apple','Banana','Grape','Orange', 'Pineapple', 'Watermelon']\n","\n","while True:\n","    # Đọc ảnh trả về từ JS\n","    js_reply = video_frame(label_html, bbox)\n","    if not js_reply:\n","        break\n","\n","    # convert JS response to OpenCV Image\n","    frame = js_to_image(js_reply[\"img\"])\n","    # print(type(frame))\n","    # print(frame.shape)\n","    # Resize để đưa vào model\n","    # frame_p = cv2.resize(frame, dsize=(128,128))\n","    # tensor = np.expand_dims(frame_p, axis=0)\n","\n","    # # Feed vào mạng\n","    result = model.predict(frame)\n","    print(result)\n","    break\n","    # class_id = np.argmax(pred)\n","    # class_name = classes[class_id]\n","\n","    # # Vẽ lên một ảnh để tẹo nữa overlay\n","\n","    # # create transparent overlay for bounding box\n","    # bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n","\n","    # bbox_array = cv2.putText(bbox_array, \"{}\".format(class_name),\n","    #                     (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n","    #                     (0, 255,0), 2)\n","\n","    # bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n","    # # convert overlay of bbox into bytes\n","    # bbox_bytes = bbox_to_bytes(bbox_array)\n","    # # update bbox so next frame gets new overlay\n","    # bbox = bbox_bytes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ru_LyBUXz6gQ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN3T3O8gHH6wAlrXNrB6g77","gpuType":"T4","mount_file_id":"1-vXuEi8e1dLeIMQiAkuxR5mp3gRG_cyJ","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
